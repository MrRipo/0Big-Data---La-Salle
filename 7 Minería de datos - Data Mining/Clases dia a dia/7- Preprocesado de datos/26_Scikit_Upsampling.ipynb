{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvzUl0jr9qFw"
      },
      "source": [
        "# Scikit Learn - Resample\n",
        "- - -"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLAjpSHE9qF1"
      },
      "source": [
        "## Resample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WG99GNc9qF2"
      },
      "source": [
        "- - -"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuPl7qFm9qF3"
      },
      "source": [
        "Algunas técnicas y su idea:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INyRSXsi9qF4"
      },
      "source": [
        "- Upsampling\n",
        "\n",
        "    Emplea un proceso de duplicar aleatoriamente las observaciones de la clase minoritaria para reforzarla."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SOFRPZg9qF4"
      },
      "source": [
        "- Downsampling\n",
        "\n",
        "    Esta metodo implica eliminar observaciones al azar de la clase mayoritaria para evitar que su presencia domine el algoritmo de aprendizaje."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cT2OP_lv9qF5"
      },
      "source": [
        "- - -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUPO-YqD9qF8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from IPython.display import set_matplotlib_formats\n",
        "set_matplotlib_formats(\"retina\")\n",
        "import warnings\n",
        "warnings.filterwarnings(action=\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bO6ho9zY9qF_"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import resample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2p0r5VFM9qF_"
      },
      "source": [
        "- - -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4gj3ha29qF_"
      },
      "outputs": [],
      "source": [
        "#Creamos datos sintéticos para trabajar con ellos\n",
        "X_0 = pd.DataFrame(np.random.randint(0,60,size=(100, 2)), columns=['A','B'])\n",
        "X_1 = pd.DataFrame(np.random.randint(40,100,size=(1000, 2)), columns=['A','B'])\n",
        "X = X_0.append(X_1).reset_index(drop=True)\n",
        "\n",
        "y_0 = pd.DataFrame(np.random.randint(0,1,size=(100, 1)), columns=['target'])\n",
        "y_1 = pd.DataFrame(np.random.randint(1,2,size=(1000, 1)), columns=['target'])\n",
        "y = y_0.append(y_1).reset_index(drop=True)\n",
        "dataset = pd.concat([X,y],axis=1)\n",
        "print(dataset.head())\n",
        "print(dataset.tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHlTaLTd9qGA"
      },
      "outputs": [],
      "source": [
        "dataset[\"target\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7AQ8OS_9qGB"
      },
      "outputs": [],
      "source": [
        "#Vemos que el dataset está muy desbalanceado\n",
        "sns.countplot(x=dataset[\"target\"]);"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x=dataset[\"A\"], y = dataset['B'], hue = dataset['target'])"
      ],
      "metadata": {
        "id": "PlJLFVp0NUOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pV297NN9qGB"
      },
      "source": [
        "#### Upsample Code Example\n",
        "- - -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IfdBjsS9qGB"
      },
      "outputs": [],
      "source": [
        "clase_mayoritaria = dataset[dataset[\"target\"] == 1]\n",
        "clase_minoritaria = dataset[dataset[\"target\"] == 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqEnl_bI9qGC"
      },
      "outputs": [],
      "source": [
        "#PRIMERA IDEA: básica\n",
        "#Hacemos que la clase minoritaria tenga 1000 instancias, pero serán una copia de\n",
        "#instancias que ya están en el dataset.\n",
        "clase_minoritaria_upsampled = resample(clase_minoritaria, n_samples=1000, random_state=1)\n",
        "print(clase_minoritaria_upsampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwCx5JKe9qGC"
      },
      "outputs": [],
      "source": [
        "upsampled_dataset = pd.concat([clase_mayoritaria, clase_minoritaria_upsampled])    \n",
        "upsampled_dataset[\"target\"].value_counts()                                   "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#A pesar de que hay más datos, si los printamos vemos que están unos encima de otros.\n",
        "sns.scatterplot(x=upsampled_dataset[\"A\"], y = upsampled_dataset['B'], hue = upsampled_dataset['target'])"
      ],
      "metadata": {
        "id": "vUVOmSUNQ2l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Em-1kV8R9qGD"
      },
      "source": [
        "#### Downsample Code Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIkVmq-I9qGD"
      },
      "source": [
        "- - -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ouudfGf9qGD"
      },
      "outputs": [],
      "source": [
        "clase_mayoritaria = dataset[dataset[\"target\"] == 1]\n",
        "clase_minoritaria = dataset[dataset[\"target\"] == 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raEje9bg9qGD"
      },
      "outputs": [],
      "source": [
        "#PRIMERA IDEA: básica\n",
        "#Eliminamos muestras aleatorias de la clase mayoritaria para quedarnos con solamente 100 muestras.\n",
        "clase_mayoritaria_downsampled = resample(clase_mayoritaria, n_samples=100, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJQ-A-f49qGE"
      },
      "outputs": [],
      "source": [
        "downsampled_dataset = pd.concat([clase_minoritaria, clase_mayoritaria_downsampled])  \n",
        "downsampled_dataset[\"target\"].value_counts() \n",
        "print(downsampled_dataset)                                    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ahora vemos que hay muchas menos muestras\n",
        "sns.scatterplot(x=downsampled_dataset[\"A\"], y = downsampled_dataset['B'], hue = downsampled_dataset['target'])"
      ],
      "metadata": {
        "id": "9Lmd6yOeRA7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8PA1Dt_9qGE"
      },
      "source": [
        "- - -\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.utils.resample.html\n",
        "- - -"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFz84Ahg9qGE"
      },
      "source": [
        "### Pero... ¿Podemos hacer algo más sofisticado? --> Data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pFiGAAb9qGE"
      },
      "source": [
        "- - -\n",
        "- SMOTE (Synthetic Minority Over-sampling Technique)\n",
        "\n",
        "    Es una técnica que consiste en sintetizar elementos para la clase minoritaria basados en los que ya existen.  \n",
        "    Funciona seleccionando aleatoriamente un punto de la clase minoritaria y calculando los k vecinos más cercanos para este punto.  \n",
        "    Los puntos sintéticos se agregan entre el punto elegido y sus vecinos."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "smote = SMOTE()\n",
        "X = dataset.drop(\"target\",1)\n",
        "y = dataset[\"target\"]\n",
        "X_res, y_res = smote.fit_resample(X, y)\n",
        "print(X_res)\n",
        "print(Counter(y_res))"
      ],
      "metadata": {
        "id": "DTU3jGH8B5L_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Analicemos cómo han quedado las muestras ahora.\n",
        "#Comparad con el plot de upsample.\n",
        "sns.scatterplot(x=X_res[\"A\"], y = X_res['B'], hue = y_res)"
      ],
      "metadata": {
        "id": "yiOry-S9RQ_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n28JtA6a9qGF"
      },
      "source": [
        "- ADASYN\n",
        "\n",
        "    Hace lo que SMOTE pero después de crear las nuevas muestras, agrega pequeños valores aleatorios para no estar correlacionadas linealmente, en otras palabras agrega dispersión."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "from collections import Counter\n",
        "\n",
        "adasyn = ADASYN()\n",
        "X_res2, y_res2 = adasyn.fit_resample(X, y)\n",
        "print(X_res2)\n",
        "print(Counter(y_res2))"
      ],
      "metadata": {
        "id": "6sZd8kM8DlgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x=X_res2[\"A\"], y = X_res2['B'], hue = y_res2)"
      ],
      "metadata": {
        "id": "2DXR7hc4Rj2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDl9PAbX9qGG"
      },
      "source": [
        "---\n",
        "https://imbalanced-learn.org"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ux1K2WtK9qGH"
      },
      "source": [
        "- - -"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4v6ogIl9qGH"
      },
      "source": [
        "## Class Weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7h3wz-J9qGH"
      },
      "source": [
        "De forma predeterminada, el valor de class_weight = None, es decir, a ambas clases se les ha asignado el mismo peso.\n",
        "También podemos darle como valor 'balanced' o podemos pasar un diccionario que contiene pesos manuales para ambas clases.\n",
        "\n",
        "Cuando class_weights = 'balanced', el modelo asigna automáticamente los pesos de clase inversamente proporcionales a sus respectivas frecuencias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66H0y1Ye9qGH"
      },
      "source": [
        "### Dataset Pima Indians Diabetes\n",
        "- - -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arkzPdso9qGH"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiCZbJ1A9qGI"
      },
      "source": [
        "- - -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2jNEM_t9qGI"
      },
      "outputs": [],
      "source": [
        "diabetes = pd.read_csv(\"https://raw.githubusercontent.com/4data-lab/datasets/master/diabetes.csv\", header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BX_LiTcg9qGI"
      },
      "outputs": [],
      "source": [
        "diabetes.columns = [\"num_preg\", \"glucose_conc\", \"diastolic_bp\", \"thickness\", \"insulin\", \"bmi\", \"diab_pred\", \"age\", \"diabetes\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVbstqyE9qGI"
      },
      "outputs": [],
      "source": [
        "diabetes.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1eCFN8d9qGJ"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x=diabetes[\"diabetes\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBJOB2v49qGJ"
      },
      "outputs": [],
      "source": [
        "X = diabetes.drop([\"diabetes\"], axis=1)\n",
        "y = diabetes[\"diabetes\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IW1MfObW9qGJ"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.30, random_state=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrap0MVF9qGJ"
      },
      "source": [
        "#### Validación Score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La F1-score tiene en cuenta por igual la precisión y el recall:\n",
        " F1 = (2 * precision * recall) / (precision + recall)"
      ],
      "metadata": {
        "id": "3vb3F7OmWUF8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJzu-YWZ9qGK"
      },
      "outputs": [],
      "source": [
        "LR = LogisticRegression()\n",
        "print(\"F1 - Datos de validation\")\n",
        "cross_val_score(LR, X_train, y_train, cv=5, scoring=\"f1\").mean().round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjC2RArP9qGK"
      },
      "source": [
        "- - -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELOHP6Ao9qGK"
      },
      "outputs": [],
      "source": [
        "#Añadimos el argumento class_weight\n",
        "LR = LogisticRegression(class_weight=\"balanced\")\n",
        "print(\"F1 - Datos de validation\")\n",
        "cross_val_score(LR, X_train, y_train, cv=5, scoring=\"f1\").mean().round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QhTyoDO9qGK"
      },
      "source": [
        "- - -"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Uy8VUz09qGK"
      },
      "source": [
        "Calcular el Class Weight:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cMS4q459qGK"
      },
      "outputs": [],
      "source": [
        "diabetes[\"diabetes\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IgeeZWU9qGL"
      },
      "outputs": [],
      "source": [
        "diabetes.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4y25tPn9qGL"
      },
      "outputs": [],
      "source": [
        "número_de_muestras = diabetes.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veXh-QjT9qGL"
      },
      "outputs": [],
      "source": [
        "número_de_muestras_clase_mayoritaria = diabetes[\"diabetes\"].value_counts()[0]\n",
        "número_de_muestras_clase_minoritaria = diabetes[\"diabetes\"].value_counts()[1]\n",
        "número_de_clases = diabetes[\"diabetes\"].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33zvqP6U9qGM"
      },
      "outputs": [],
      "source": [
        "W0 = (número_de_muestras / (número_de_clases * número_de_muestras_clase_mayoritaria)).round(3)\n",
        "W1 = (número_de_muestras / (número_de_clases * número_de_muestras_clase_minoritaria)).round(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DK_Uz-rR9qGM"
      },
      "outputs": [],
      "source": [
        "print(\"W0:\", W0)\n",
        "print(\"W1:\", W1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKr7Gd5X9qGM"
      },
      "outputs": [],
      "source": [
        "LR = LogisticRegression(class_weight={0: 0.768, 1: 1.433})\n",
        "print(\"F1 - Datos de validation\")\n",
        "cross_val_score(LR, X_train, y_train, cv=5, scoring=\"f1\").mean().round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItMy4ejt9qGM"
      },
      "source": [
        "#### Test Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVUcE4RU9qGN"
      },
      "outputs": [],
      "source": [
        "LR.fit(X_train, y_train)\n",
        "y_test_pred = LR.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEq8I6gM9qGN"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "matriz_de_confusión = confusion_matrix(y_test, y_test_pred)\n",
        "print(matriz_de_confusión)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRpI6ft59qGN"
      },
      "outputs": [],
      "source": [
        "VN = matriz_de_confusión[0][0]\n",
        "FP = matriz_de_confusión[0][1]\n",
        "FN = matriz_de_confusión[1][0]\n",
        "VP = matriz_de_confusión[1][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdrI-LBl9qGN"
      },
      "outputs": [],
      "source": [
        "print (\"Verdaderos Negativos \\t\", VN)\n",
        "print (\"Falsos Positivos \\t\", FP)\n",
        "print (\"Falsos Negativos \\t\", FN)\n",
        "print (\"Verdaderos Positivos \\t\", VP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGZP2S4S9qGN"
      },
      "source": [
        "#### ACCURACY (aka Exactitud):\n",
        "Porcentaje de predicciónes correctas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdSgAZ4a9qGN"
      },
      "outputs": [],
      "source": [
        "print(((VP+VN)/(VP+VN+FP+FN)).round(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NG1l8eUk9qGN"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, y_test_pred).round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Z8M1l559qGO"
      },
      "source": [
        "- - -\n",
        "| *Matriz Confusión*        | Predicción Negativa    | Predicción Positiva     |\n",
        "| -------------             | :-------------:          | :-------------:           |\n",
        "| **Observación Negativa** | Verdaderos Negativo (VN)  | Falsos Positivo (FP)      |\n",
        "| **Observación Positiva** | Falsos Negativo (FN)      | Verdaderos Positivos (VP) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uA8rNnX39qGO"
      },
      "source": [
        "#### ESPECIFICIDAD (aka Specificity):\n",
        "Porcentaje de casos de observaciones negativas detectadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqvRp_P39qGO"
      },
      "outputs": [],
      "source": [
        "print((VN/(VN+FP)).round(2)) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9PsGKBK9qGO"
      },
      "source": [
        "#### SENSIBILIDAD (aka Recall):  \n",
        "Porcentaje de casos de observaciones positivas detectadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYsPPoV09qGO"
      },
      "outputs": [],
      "source": [
        "print((VP/(VP+FN)).round(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emdx1aJf9qGP"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import recall_score\n",
        "recall_score(y_test, y_test_pred).round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1be_jEm9qGQ"
      },
      "source": [
        "- - -"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aH7jWG5t9qGQ"
      },
      "source": [
        "#### PRECISIÓN (aka Precision): \n",
        "Porcentaje de predicciones de verdaderos positivos correctos"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "tFDLGMFo9qGQ"
      },
      "source": [
        "print(()).round(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJZTQlBB9qGQ"
      },
      "outputs": [],
      "source": [
        "print((VP/(VP+FP)).round(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpacsqUy9qGQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score\n",
        "precision_score(y_test, y_test_pred).round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANVsM8gx9qGR"
      },
      "source": [
        "#### F1 (aka balanced F-score):  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-p9-TEU9qGR"
      },
      "source": [
        "Esta es otra métrica muy empleada porque nos resume la precisión y sensibilidad en una sola métrica por ello es de gran utilidad cuando la distribución de las clases está desbalanceada.\n",
        "\n",
        "A diferencia de la exactitud, que se ve muy afectada por una gran cantidad de Verdaderos Negativos que en la mayoría de los casos no son de nuestro mayor interes, los Falsos Negativos y Falsos Positivos usualmente tienen impacto en nuestra solución. "
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "VezhXCvL9qGR"
      },
      "source": [
        "### F1 = 2 * (Recall * Precision) / (Recall + Precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HD2mipZ69qGR"
      },
      "outputs": [],
      "source": [
        "Recall = (VP/(VP+FN)).round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUz4fFLJ9qGR"
      },
      "outputs": [],
      "source": [
        "Precision = (VP/(VP+FP)).round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zu_owLX39qGR"
      },
      "outputs": [],
      "source": [
        "print((2 * (Recall * Precision) / (Recall + Precision)).round(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuLuaxx29qGS"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_test, y_test_pred).round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0iRkKvY9qGS"
      },
      "source": [
        "- - -"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRgJtKiX9qGS"
      },
      "source": [
        "### Reporte de Clasificación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mx6lrwoV9qGS"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsK0LTDR9qGS"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaCkYhjf9qGS"
      },
      "source": [
        "- - -"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3o9dk9V9qGS"
      },
      "source": [
        "    Support es el número de registros de cada clase en los datos del reporte de clasificación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aE7-Q_gj9qGS"
      },
      "outputs": [],
      "source": [
        "y_test.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQgc96MB9qGT"
      },
      "source": [
        "- - -"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}