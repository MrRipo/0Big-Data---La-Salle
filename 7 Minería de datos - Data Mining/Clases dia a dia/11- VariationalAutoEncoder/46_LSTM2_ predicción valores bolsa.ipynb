{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP/Xtagwl7RLobVWfyYFdZx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Usaremos una RNN del tipos LSTM para predecir los valores de bolsa de una compañía. Haremos servir los valores de la bolsa NASDAQ (National Association of Securities Dealer Automated Quotation), que es la más grande de Estados Unidos."],"metadata":{"id":"TLn7vJlo0187"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"JxXzaICO0wE2"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.models import Sequential\n","from keras.layers import LSTM, Dense\n","import pandas as pd"]},{"cell_type":"code","source":["# Leemos el conjunto de datos, que descargaremos utilizando la biblioteca yfinance\n","import yfinance as yf\n","\n","# Descargamos los datos de Google de NASDAQ\n","# Leeremos los datos desde el año 2012 hasta enero de 2024\n","# Empresas posibles para consultar --> Google: GOOGL, Amazon: AMZN, Apple: AAPL, Netflix: NFLX\n","# Podéis consultar el acrónimo de otras empresas en https://es.wikipedia.org/wiki/NASDAQ-100\n","empresa = 'GOOGL'\n","datos = yf.download(empresa, start='2012-01-01', end='2024-01-01')\n","\n","# Muestra las primeras filas de los datos\n","print(datos.head())\n"],"metadata":{"id":"HERXuWOg09Hi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Nos quedamos con los datos de cierre y los visualizamos.\n","datos = datos['Close']\n","plt.plot(datos);\n","print(datos.head())\n"],"metadata":{"id":"IDTe5aZR1dO7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Normalizamos los datos\n","escalador = MinMaxScaler()\n","array_de_datos = np.array(datos)\n","datos_escalados = escalador.fit_transform(array_de_datos.reshape(-1, 1))\n","print(\"Los datos más antiguos:\")\n","print(datos_escalados[0:5])\n","print(\"Los datos más recientes:\")\n","print(datos_escalados[-5::])\n"],"metadata":{"id":"LZLEgCgx1x84"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dividimos las muestras en entrenamiento y test\n","tamaño_entrenamiento = int(len(datos_escalados) * 0.8)\n","tamaño_prueba = len(datos_escalados) - tamaño_entrenamiento\n","datos_entrenamiento = datos_escalados[0:tamaño_entrenamiento, :]\n","datos_prueba = datos_escalados[tamaño_entrenamiento:len(datos_escalados), :1]\n"],"metadata":{"id":"RLYaOvZ814iv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Creamos pequeñas series temporales para entrenar y testear\n","def crear_series_temporales(datos, longitud_serie):\n","    X, Y = [], []\n","    for i in range(0, len(datos) - longitud_serie - 1):\n","        serie_X = datos[i:(i + longitud_serie)]  # Secuencia de datos hasta el momento actual\n","        serie_Y = datos[i + longitud_serie]  # Valor siguiente a predecir\n","        X.append(serie_X)\n","        Y.append(serie_Y)\n","    return np.array(X), np.array(Y)\n","\n","\n","longitud_serie = 10  # Longitud de la ventana de la serie temporal\n","X_train, y_train = crear_series_temporales(datos_entrenamiento, longitud_serie)\n","X_test, y_test = crear_series_temporales(datos_prueba, longitud_serie)\n","print(\"Los datos de entrenamiento tienen la forma {}\".format(X_train.shape))\n","print(\"Los valores a predecir de entrenamiento (y) tienen la forma {}\".format(y_train.shape))\n","print(\"Los datos de prueba tienen la forma {}\".format(X_test.shape))\n","print(\"Los valores a predecir de prueba (y) tienen la forma {}\".format(y_test.shape))\n"],"metadata":{"id":"f9sBrGCs1_EA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Eliminamos la última dimensión:\n","X_train = X_train.reshape(X_train.shape[0], X_train.shape[1])\n","y_train = y_train.reshape(y_train.shape[0])\n","X_test = X_test.reshape(X_test.shape[0], X_test.shape[1])\n","y_test = y_test.reshape(y_test.shape[0])\n"],"metadata":{"id":"G7o1lff32GRX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Definimos y compilamos el modelo LSTM\n","modelo = Sequential()\n","modelo.add(LSTM(50, activation='relu', input_shape=(X_train.shape[1], 1)))\n","modelo.add(Dense(1))\n","modelo.compile(optimizer='adam', loss='mse')\n"],"metadata":{"id":"jRgdpEpb2KdA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Entrenamos el modelo\n","modelo.fit(X_train, y_train, epochs=10, batch_size=64, verbose=1)\n","\n","# Evaluamos el modelo\n","pérdida_entrenamiento = modelo.evaluate(X_train, y_train, verbose=0)\n","pérdida_prueba = modelo.evaluate(X_test, y_test, verbose=0)\n","print('Pérdida de entrenamiento:', pérdida_entrenamiento)\n","print('Pérdida de prueba:', pérdida_prueba)\n"],"metadata":{"id":"n3FIWMYR2Qu3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Usamos los datos para predecir\n","predicciones_entrenamiento = modelo.predict(X_train)\n","predicciones_prueba = modelo.predict(X_test)\n","# Desnormalizamos las predicciones\n","predicciones_entrenamiento = escalador.inverse_transform(predicciones_entrenamiento)\n","predicciones_prueba = escalador.inverse_transform(predicciones_prueba)\n","# Creamos nuevos DataFrames con el índice original\n","predicciones_entrenamiento = pd.DataFrame(predicciones_entrenamiento, index=datos.index[:len(predicciones_entrenamiento)])\n","predicciones_prueba = pd.DataFrame(predicciones_prueba, index=datos.index[len(datos)-len(predicciones_prueba):])\n"],"metadata":{"id":"CxrPJeSd2Wbv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Gráfica de todas las predicciones\n","plt.plot(datos, label='Datos reales')\n","plt.plot(predicciones_entrenamiento, label='Predicciones entrenamiento')\n","plt.plot(predicciones_prueba, label='Predicciones prueba')\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"Ml89DJ2e2cY_"},"execution_count":null,"outputs":[]}]}