{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYysdyb-CaWM"
      },
      "source": [
        "# Convolutional Neural Networks\n",
        "- - -"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR0EdgrLCaWR"
      },
      "source": [
        "Vamos a trabajar con un conjunto de datos de imágenes de artículos de ropa.\n",
        "\n",
        "Consiste en un conjunto de 70.000 ejemplos. \n",
        "\n",
        "Cada ejemplo es una imagen en escala de grises de 28x28, asociada a una target de 10 clases.\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://1.bp.blogspot.com/-AIPR5UuydTY/WbCLlGEmoAI/AAAAAAAAA2U/Teu6q2FF9LslUL6t6Qn5YjzGWNfHC7y7wCLcBGAs/w1200-h630-p-k-no-nu/fashion-mnist-sprite.png\"  width=\"750\">\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "    </td></tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlTsUalI7AN4"
      },
      "source": [
        "Importaremos nuestras librerías:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESh6Dw2fso_V"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import set_matplotlib_formats\n",
        "set_matplotlib_formats('retina')\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzLKpmZICaWN"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh2m124t7Mlt"
      },
      "source": [
        "- - -"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nzZwUOb7P6L"
      },
      "source": [
        "Importaremos el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7mxzA1ArUM4"
      },
      "outputs": [],
      "source": [
        "fashion = pd.read_csv('https://raw.githubusercontent.com/4data-lab/datasets/master/fashion.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogKKOaeKuCqn"
      },
      "outputs": [],
      "source": [
        "print('Número de filas: {}'.format(fashion.shape[0]))\n",
        "print('Número de columnas: {}'.format(fashion.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8tw1I4Wpg83"
      },
      "outputs": [],
      "source": [
        "fashion.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2m7WL0Ti7yD3"
      },
      "outputs": [],
      "source": [
        "fashion.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBzOCvhiDicj"
      },
      "outputs": [],
      "source": [
        "#Miramos si las clases están balanceadas\n",
        "sns.countplot(x=\"class\", data=fashion, palette=\"Set3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-HyeGjwv6wR"
      },
      "outputs": [],
      "source": [
        "X = fashion.drop('class', 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pr-3HArMy3AC"
      },
      "outputs": [],
      "source": [
        "y = fashion['class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gwx2zUp0AsG"
      },
      "outputs": [],
      "source": [
        "train_images, test_images, train_labels, test_labels = train_test_split(X, y, test_size=10000, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4oIf6zvf23x"
      },
      "source": [
        "- train_images: información de las imágenes de entrenamiento\n",
        "- train_labels: clase del target de entrenamiento\n",
        "\n",
        "\n",
        "- test_images: informacion de imágenes de test\n",
        "- test_labels: clase del target de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zW5k_xz1CaWX"
      },
      "outputs": [],
      "source": [
        "train_images.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTb1UggCTW2P"
      },
      "source": [
        "Como podemos ver en este caso, cuando estamos interpretando el shape de train_images, podemos ver que se trata de un conjunto de 60000 imágenes de 28 x 28 (784), que es la cantidad de pixeles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1R4pEauUMRU"
      },
      "outputs": [],
      "source": [
        "train_labels.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIAcvQqMCaWf"
      },
      "source": [
        "Por otra parte, si miramos el shape de train_labels, podemos ver que corresponde al target de entrenamiento de train_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKnCTHz4CaWg"
      },
      "outputs": [],
      "source": [
        "print(train_labels[:15])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EBppe1rVuA1"
      },
      "source": [
        "Si miramos el target, podemos ver que se trata de números enteros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES6uQoLKCaWr"
      },
      "source": [
        "- - -\n",
        "Ahora veamos cómo se ve una de las imágenes de nuestro conjunto de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mdKFh9VzcBL"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.imshow(np.reshape(train_images.values[1], (28,28)), cmap='gray');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8vOXID_YsZ8"
      },
      "source": [
        "Los valores de nuestra imagen estan compendidos entre 0 y 255, ya que se trata de una imagen en escala de grises."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiWHrPPZ2CtE"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.imshow(np.reshape(train_images.values[3], (28,28)), cmap='gray')\n",
        "plt.colorbar();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYuu1Bqviq6x"
      },
      "source": [
        "En el target tenemos valores que van de 0 a 9 y representan a las clases, en este caso a los tipos de ropa:\n",
        "\n",
        "- 0\tT-shirt/top\n",
        "\n",
        "- 1\tTrouser\n",
        "\n",
        "- 2\tPullover\n",
        "\n",
        "- 3\tDress\n",
        "\n",
        "- 4\tCoat\n",
        "\n",
        "- 5\tSandal\n",
        "\n",
        "- 6\tShirt\n",
        "\n",
        "- 7\tSneaker\n",
        "\n",
        "- 8\tBag\n",
        "\n",
        "- 9\tAnkle boot\n",
        "\n",
        "- - -"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee638AlnCaWz"
      },
      "source": [
        "Con un código un poco más complejo, podemos generar un subplot. Es decir, uno o más plots dentro otro.\n",
        "\n",
        "Pasaremos las primeras 20 imágenes y a su vez las etiquetaremos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UuzQSB35r2V"
      },
      "outputs": [],
      "source": [
        "etiquetas = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufk5pMa72C-9"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for imagenes in range(20):\n",
        "    plt.subplot(5,4,imagenes+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(np.reshape(train_images.values[imagenes], (28,28)), cmap='gray')\n",
        "    plt.xlabel(etiquetas[train_labels.values[imagenes]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49puuGTGcgb6"
      },
      "source": [
        "5  sera el número de filas\n",
        "\n",
        "4 sera el número de columnas\n",
        "\n",
        "imagenes + 1 sera el número de subdivisiones activas del subplot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJBOCRIM1jzT"
      },
      "source": [
        "- - - \n",
        "A continuación, prepararemos nuestros datos de entrada.\n",
        "\n",
        "Debemos modificar la estructura de nuestros datos (**train_images** y **test_images**) a la forma que nuestro modelo espera.\n",
        "\n",
        "El primer número es el número de imágenes (60000 para train_images y 10000 para test_images).\n",
        "Luego viene la forma de cada imagen (28x28). El último número es 1, que significa que las imágenes están en escala de grises. Si fueran imágenes a color, tendríamos tres matrices de 28x28."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdT95PvQQsw1"
      },
      "outputs": [],
      "source": [
        "train_images = train_images.values.reshape(60000,28,28,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgGnQc3YRQTa"
      },
      "outputs": [],
      "source": [
        "train_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVwO6qbMvS-D"
      },
      "outputs": [],
      "source": [
        "test_images = test_images.values.reshape(10000,28,28,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsmdHg4A2DQ-"
      },
      "outputs": [],
      "source": [
        "test_images.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxdNcTpptxa5"
      },
      "source": [
        "\n",
        "Escalaremos nuestros datos entre 0 y 1. Para ello simplemente podemos realizar una división por 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jwWQpjlXBSy"
      },
      "outputs": [],
      "source": [
        "train_images = train_images / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlIk_KhyXHmI"
      },
      "outputs": [],
      "source": [
        "test_images = test_images / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59veuiEZCaW4"
      },
      "source": [
        "- - -\n",
        "- - -\n",
        "El tipo de modelo que usaremos es secuencial. Que permite construir un modelo capa por capa.\n",
        "\n",
        "Usamos la función add() para agregar capas a nuestro modelo.\n",
        "\n",
        "Las capas Conv2D son capas de convolución que tratarán con nuestras imágenes de entrada y que se ven como matrices bidimensionales.\n",
        "\n",
        "El 64 en la primera capa y 32 en la segunda capa son el número de neuronas en cada capa. \n",
        "Este número se puede ajustar para que sea mayor o menor.\n",
        "\n",
        "El tamaño del kernel es el tamaño de la matriz de filtro para nuestra convolución. \n",
        "Un kernel de 3 significa que tendremos una matriz de filtro de 3x3.\n",
        "\n",
        "Nuestra primera capa también toma una forma de entrada, esta es la forma de cada imagen de entrada, (28,28,1)\n",
        "\n",
        "Entre las capas Conv2D y la capa dense, hay una capa Flatten. Esta capa sirve como una conexión entre la convolución y las capas densas. Lo que está haciendo es pasar de un vector 2D a un vector de una única dimensión (aplana la matriz).\n",
        "\n",
        "Dense es el tipo de capa que usaremos para nuestra capa de salida, es un tipo de capa estándar que se usa en muchos casos para redes neuronales.\n",
        "\n",
        "Tendremos 10 neuronas en nuestra capa de salida, uno para cada resultado posible (0–9).\n",
        "\n",
        "La activación función de activación de la última capa es softmax, que hace que la suma de salida sea de hasta 1 para que la salida se pueda interpretar como la probabilidad de que la entrada pertenezca a una clase concreta.\n",
        "Así pues, cada neurona contiene una puntuación que indica la probabilidad de que la imagen actual pertenezca a una de las 10 clases.\n",
        "El modelo luego hará su predicción en función de qué clase tiene la mayor probabilidad.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-ZQjj-LWukU"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) \n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfLo1CZk7Vqi"
      },
      "source": [
        "- - -\n",
        "- - -\n",
        "\n",
        "Antes de que el modelo esté listo para que lo entrenemos, necesitara algunos ajustes. \n",
        "\n",
        "\n",
        "- Optimizador: Usaremos 'adam' que actualmente es el optimizador de referencia. Adam (Adaptive Moment Estimation) ajusta la tasa de aprendizaje durante el entrenamiento.\n",
        "- Función de coste o de error: Usaremos sparse_categorical_crossentropy, que es la opción más común para la clasificación. Una puntuación más baja indica que el modelo está funcionando mejor.\n",
        "\n",
        "  - Si tu target son dummies, utiliza categorical_crossentropy.\n",
        "\n",
        "    [1,0,0]\n",
        "\n",
        "    [0,1,0]\n",
        "\n",
        "    [0,0,1]\n",
        "\n",
        "  - Si tu target son números enteros, utiliza sparse_categorical_crossentropy.\n",
        "  \n",
        "    1\n",
        "  \n",
        "    2\n",
        "  \n",
        "    3\n",
        "\n",
        "-  Métricas: utilizaremos la accuracy para interpretar fácilmente los resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lhan11blCaW7"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(model, \"NuestraCNN.png\", show_shapes=True)"
      ],
      "metadata": {
        "id": "bXslTF-w8_pf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKF6uW-BCaW-"
      },
      "source": [
        "Ahora empezaremos a entrenar a nuestro modelo realizandole un Fit, para que aprenda de los datos de entrenamiento.\n",
        "\n",
        "El número de épocas es el número de veces que el modelo recorrerá los datos.\n",
        "\n",
        "Cuantas más épocas ejecutemos, más mejorará el modelo, hasta cierto punto. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYGZXeqrPFbK"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_images, train_labels, validation_split = 0.1, batch_size = 256, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBfloP1VhmFz"
      },
      "outputs": [],
      "source": [
        "accuracy = model.evaluate(train_images, train_labels)\n",
        "\n",
        "print(accuracy[1], \"Accuracy en Train\",)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEw4bZgGCaXB"
      },
      "source": [
        "Ahora testearemos nuestro modelo con datos de test, para ver como lo hace con datos que no ha visto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEBZXBn4U4UB"
      },
      "outputs": [],
      "source": [
        "accuracy = model.evaluate(test_images, test_labels)\n",
        "\n",
        "print(accuracy[1], \"Accuracy en Test\",)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsoS7CPDCaXH"
      },
      "source": [
        "Probaremos alguna predicciones con nuestro modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gl91RPhdCaXI"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DmJEUinCaXK"
      },
      "outputs": [],
      "source": [
        "predictions[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hw1hgeSCaXN"
      },
      "source": [
        "El anterior array describe la confianza del modelo al clasificar una clase.\n",
        "\n",
        "Realizando un argmax, podemos obtener el valor de la predicción."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsqenuPnCaXO"
      },
      "outputs": [],
      "source": [
        "print(np.argmax(predictions[2]), \"Valor de la predicción\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6Mvba9rhmF1"
      },
      "outputs": [],
      "source": [
        "print(test_labels.values[2], \"Valor real esperado\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmeg-CgVhmF1"
      },
      "source": [
        "- - -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sd7Pgsu6CaXP"
      },
      "outputs": [],
      "source": [
        "def plot_results(x):\n",
        "    print(np.argmax(predictions[x]), \"Valor de la predicción\")\n",
        "    print(test_labels.values[x], \"Valor real esperado\")\n",
        "    plt.bar(range(10), predictions[x])\n",
        "    plt.xticks(range(10))\n",
        "    plt.ylim([0, 1])\n",
        "    plt.grid(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cs2YJh5p0qhV"
      },
      "outputs": [],
      "source": [
        "plot_results(21)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "IdMDxvx9498q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_predictions = np.argmax(predictions,axis = 1)\n",
        "confusion_matrix(test_labels, label_predictions)\n"
      ],
      "metadata": {
        "id": "Rer47DKt5lJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_labels, label_predictions))"
      ],
      "metadata": {
        "id": "2xNFfbox62B-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evolución de la accuracy y la loss por cada epoch:"
      ],
      "metadata": {
        "id": "7AKir5K8a_Si"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KT4CpYv-hmF2"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6TGL2lmYa3n5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "También podemos guardar el modelo"
      ],
      "metadata": {
        "id": "Ssm4HaOPccaZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DW1VCBZhmF2"
      },
      "outputs": [],
      "source": [
        "# Guardar el Modelo\n",
        "model.save('my_CNN.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Abre el modelo entrenado desde un archivo\n",
        "new_model = keras.models.load_model('my_CNN.h5')"
      ],
      "metadata": {
        "id": "LUoi9eDBch6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = new_model.evaluate(test_images, test_labels)\n",
        "\n",
        "print(accuracy[1], \"Accuracy en Test en el modelo guardado\",)"
      ],
      "metadata": {
        "id": "oEihCWttcsTW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}