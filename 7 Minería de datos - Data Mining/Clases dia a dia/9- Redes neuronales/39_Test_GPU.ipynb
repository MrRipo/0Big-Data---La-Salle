{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time"
      ],
      "metadata": {
        "id": "U0Qv9yEjz3x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Declaramos dos matrices muy grandes\n",
        "x = torch.FloatTensor(10000, 500).normal_()\n",
        "w = torch.FloatTensor(20000, 500).normal_()\n",
        "print(x.shape)\n",
        "print(w.shape)"
      ],
      "metadata": {
        "id": "lroHkS_Rz-Gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Multiplicamos las matrices en CPU\n",
        "x = x.to('cpu')\n",
        "w = w.to('cpu')\n",
        "for i in range(10):\n",
        "  a = time.perf_counter()\n",
        "  y = x.mm(w.t()) #multiplicamos matriz x por matriz w.\n",
        "  b = time.perf_counter()\n",
        "  print('Tiempo en CPU {} segundos'.format(b - a))"
      ],
      "metadata": {
        "id": "fbefRShKz9Gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Multiplicamos las matrices en GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "x = x.to(device)\n",
        "w = w.to(device)\n",
        "for i in range(10):\n",
        "  a = time.perf_counter()\n",
        "  y = x.mm(w.t()) #multiplicamos matriz x por matriz w.\n",
        "  b = time.perf_counter()\n",
        "  print('Tiempo en GPU {} segundos'.format(b - a))"
      ],
      "metadata": {
        "id": "IyT43F4M0hgH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}